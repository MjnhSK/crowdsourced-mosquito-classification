{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnyugen\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "wandb_logger = WandbLogger(\n",
    "    project='CLIP',\n",
    "    log_model='all',\n",
    "    name='CLIP_fold',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.16 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n",
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/pydantic/main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/pydantic/main.py:364: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "INFO:root:Loaded ViT-L-14 model config.\n",
      "INFO:root:Loading pretrained ViT-L-14 weights (datacomp_xl_s13b_b90k).\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch as th\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import src.classification as lc\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from src.experiments import ExperimentMosquitoClassifier\n",
    "\n",
    "def callbacks() -> List[Callback]:\n",
    "    return [\n",
    "        ModelCheckpoint(\n",
    "            dirpath= \"/home/pc2/Downloads/AI-Crowd/Mosquito-Classifiction/experiments/checkpoints/CLIP_folds/f1/\",\n",
    "            monitor=\"val_f1_score\",\n",
    "            mode=\"max\",\n",
    "            save_top_k=2,\n",
    "            save_last=False,\n",
    "            save_weights_only=True,\n",
    "            filename=\"{epoch}-{val_loss}-{val_f1_score}-{val_multiclass_accuracy}\",\n",
    "        ),\n",
    "        EarlyStopping(monitor=\"val_f1_score\", mode=\"max\", patience=5),\n",
    "        # LogPredictionsCallback(),\n",
    "    ]\n",
    "\n",
    "CLASS_DICT = {\n",
    "    \"albopictus\":           th.tensor([1, 0, 0, 0], dtype=th.float),\n",
    "    \"culex\":                th.tensor([0, 1, 0, 0], dtype=th.float),\n",
    "    \"japonicus/koreicus\":   th.tensor([0, 0, 1, 0], dtype=th.float),\n",
    "    \"culiseta\":             th.tensor([0, 0, 0, 1], dtype=th.float),\n",
    "}\n",
    "\n",
    "class_dict = {\n",
    "    \"albopictus\":           th.tensor([1, 0, 0, 0, 0], dtype=th.float),\n",
    "    \"culex\":                th.tensor([0, 1, 0, 0, 0], dtype=th.float),\n",
    "    \"japonicus/koreicus\":   th.tensor([0, 0, 1, 0, 0], dtype=th.float),\n",
    "    \"culiseta\":             th.tensor([0, 0, 0, 1, 0], dtype=th.float),\n",
    "    \"mosquito\":             th.tensor([0, 0, 0, 0, 1], dtype=th.float)\n",
    "} \n",
    "\n",
    "dataset = 'datacomp_xl_s13b_b90k'\n",
    "aug = 'hca'\n",
    "bs = 16\n",
    "img_size = (224, 224)\n",
    "# img_size = (299, 299)\n",
    "shift_box = False\n",
    "\n",
    "img_dir = \"\"\n",
    "\n",
    "# Anno 2: F1\n",
    "f = 1\n",
    "val_annotations_csv = f\"../data_round_2/Folds/val_fold_{f}.csv\"\n",
    "train_annotations_csv = f\"../data_round_2/Folds/train_fold_{f}.csv\"\n",
    "test_annotations_csv = f\"../data_round_2/mosAlert_new_annotation_2/test_annotation_2.csv\"\n",
    "\n",
    "\n",
    "val_df = pd.read_csv(val_annotations_csv)\n",
    "train_df = pd.read_csv(train_annotations_csv)\n",
    "test_df = pd.read_csv(test_annotations_csv)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True) # need shuffle test set\n",
    "\n",
    "\n",
    "train_dataloader, _, _ = ExperimentMosquitoClassifier(\".\", \"\",\n",
    "                                                       class_dict=CLASS_DICT,\n",
    "                                                       class_dict_test=class_dict).get_dataloaders(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    dataset,\n",
    "    aug,\n",
    "    bs,\n",
    "    img_size,\n",
    "    shift_box,\n",
    ")\n",
    "\n",
    "_, val_dataloader, _ = ExperimentMosquitoClassifier(img_dir, \"\",\n",
    "                                                       class_dict=CLASS_DICT,\n",
    "                                                       class_dict_test=class_dict).get_dataloaders(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    test_df,\n",
    "    dataset,\n",
    "    aug,\n",
    "    bs,\n",
    "    img_size,\n",
    "    shift_box,\n",
    ")\n",
    "\n",
    "model = lc.MosquitoClassifier(\n",
    "    bs=16,\n",
    "    head_version=7,\n",
    "    freeze_backbones=False,\n",
    "    label_smoothing=0.1,\n",
    "    data_aug=\"hca\",\n",
    "    epochs=15,\n",
    "    max_steps=60000,\n",
    "    use_ema=True,\n",
    "    n_classes=4,\n",
    "    loss_func=\"ce\",\n",
    "    # model_name=\"hf-hub:imageomics/bioclip\",\n",
    "    #dataset=\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['japonicus/koreicus', 'culiseta', 'culex', 'albopictus'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[\"class_label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# hca_callbacks = callbacks()\n",
    "th.set_float32_matmul_precision(\"high\")\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    max_epochs=model.hparams.epochs,\n",
    "    # logger=True,\n",
    "    deterministic=True,  # maybe we should add this\n",
    "    callbacks=callbacks(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.18.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240929_022710-c8vgs8qa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nyugen/CLIP%20/runs/c8vgs8qa' target=\"_blank\">CLIP_fold</a></strong> to <a href='https://wandb.ai/nyugen/CLIP%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nyugen/CLIP%20' target=\"_blank\">https://wandb.ai/nyugen/CLIP%20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nyugen/CLIP%20/runs/c8vgs8qa' target=\"_blank\">https://wandb.ai/nyugen/CLIP%20/runs/c8vgs8qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type           | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | cls  | CLIPClassifier | 303 M  | train\n",
      "1 | ema  | EMA            | 303 M  | train\n",
      "------------------------------------------------\n",
      "607 M     Trainable params\n",
      "0         Non-trainable params\n",
      "607 M     Total params\n",
      "2,431.767 Total estimated model params size (MB)\n",
      "278       Modules in train mode\n",
      "277       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3f39d3a8244319a0082e91ed6ee9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/torcheval/metrics/functional/classification/accuracy.py:275: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:231.)\n",
      "  num_correct = mask.new_zeros(num_classes).scatter_(0, target, mask, reduce=\"add\")\n",
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9395b29e247243e2bec8840f0ffb5ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc2/miniconda3/envs/yolo/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7000658fb44e7cb47d89cbd788ed02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4049190cb46f4a14edefad00e2f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4853f01f1e6a44b48426c4273f67b7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e3b4733372417a9bdb200aef1f6483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e869bb724740a081d23eeeb12b0588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0554acbc2f0c44a6a9943072dbff12dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008d0c7df1154de9a7720a4caf1459f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9e401cd1054118b78dea16e2732f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867cd52f07604e02b8dca45f6da35056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978457e5385b4c21942e8f106d8922bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f962dd7c1a4a719eb8bd7f1d251478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e7c8db4b08494bb20b01d1c301ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2666a50055244081ad30f234574f92af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e23ad1a7ab44038f3f7d4541812f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef83752c4c6486699a844747d832855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab0f160a6e94d99b5ce91e3b860f86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='20874.147 MB of 20874.147 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▆▆▇▇▇▇████████</td></tr><tr><td>train_f1_score</td><td>▁▆▆▇▇▇▇█▇▇█████</td></tr><tr><td>train_loss</td><td>█▆▄▄█▆▅▅▄▅▄▆▅▂▇▁▄▅▃▃▄▂▄▃▆▅▄▃▄▃▄▃▅▄▄▃▆▆▅▄</td></tr><tr><td>train_multiclass_accuracy</td><td>▁▆▆▇▇▇▇████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▇▇▇██▇██▇█</td></tr><tr><td>val_f1_score</td><td>▁▅▇▇▇▇▇▇▇▇▇█▇▇█</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_multiclass_accuracy</td><td>▁▇█▆▆▆▇▅▅▅▄▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_accuracy</td><td>0.6161</td></tr><tr><td>train_f1_score</td><td>0.62766</td></tr><tr><td>train_loss</td><td>0.86847</td></tr><tr><td>train_multiclass_accuracy</td><td>0.61608</td></tr><tr><td>trainer/global_step</td><td>16439</td></tr><tr><td>val_accuracy</td><td>0.97471</td></tr><tr><td>val_f1_score</td><td>0.93496</td></tr><tr><td>val_loss</td><td>0.56683</td></tr><tr><td>val_multiclass_accuracy</td><td>0.91364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CLIP_fold</strong> at: <a href='https://wandb.ai/nyugen/CLIP%20/runs/c8vgs8qa' target=\"_blank\">https://wandb.ai/nyugen/CLIP%20/runs/c8vgs8qa</a><br/> View project at: <a href='https://wandb.ai/nyugen/CLIP%20' target=\"_blank\">https://wandb.ai/nyugen/CLIP%20</a><br/>Synced 6 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240929_022710-c8vgs8qa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
